{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "**Цель исследования:** обучить модель классифицировать комментарии на позитивные и негативные, значение метрики качества *F1* обученной модели  должна быть не меньше 0.75. \n",
    "\n",
    "**Ход исследования:**\n",
    "\n",
    "1. *Подготовка данных:*\n",
    "\n",
    "- Открыть файл и загрузить данные с использованием библиотеки pandas;\n",
    "- Провести первичную оценку данных: использовать методы head(), info() для изучения общей информации;\n",
    "- Провести лемматизацию и очистку данных.\n",
    "\n",
    "2. *Обучение:*\n",
    "\n",
    "- Избавиться от дисбаланса классов;\n",
    "- Построить пайплайн;\n",
    "- Оценить метрику F1 на тестовой выборке для лучше модели.\n",
    "\n",
    "*Общий вывод:*\n",
    "\n",
    "- Написать общий вывод, в котором суммировать основные результаты исследования и сделать ключевые выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re \n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"/datasets/toxic_comments.csv\")\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv(r\"C:\\Users\\Тадевос\\Tadevos\\USER\\Desktop\\Курсы\\Модуль 4\\Датасеты к проектам\\МО для текстов\\toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Тадевос\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Тадевос\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Тадевос\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "Очищенный и лемматизированный текст: Explanation Why the edit make under my username Hardcore Metallica Fan be revert They weren t vandalisms just closure on some GAs after I vote at New York Dolls FAC And please don t remove the template from the talk page since I m retire now\n"
     ]
    }
   ],
   "source": [
    "corpus = df['text'].values\n",
    "\n",
    "# Создание экземпляра лемматизатора WordNet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Функция лемматизации текста с указанием части речи\n",
    "def lemmatize(text):\n",
    "    words = word_tokenize(text)  # Токенизация текста\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]  # Лемматизация с указанием части речи (глагол)\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text\n",
    "\n",
    "# Функция очистки текста от спецсимволов\n",
    "def clear_text(text):\n",
    "    no_special_chars_text = re.sub(r'[^a-zA-Z]', ' ', text)  # Удаление спецсимволов, оставляем только латинские буквы\n",
    "    clear_text = \" \".join(no_special_chars_text.split()) \n",
    "    return clear_text\n",
    "\n",
    "# Применение функции к тексту и добавление столбца clean_text в DataFrame\n",
    "df['lemm_text'] = df['text'].apply(lambda x: lemmatize(clear_text(x)))\n",
    "\n",
    "# Приведение текста в столбце 'lemm_text' к нижнему регистру\n",
    "df['lemm_text'] = df['lemm_text'].str.lower()\n",
    "\n",
    "print(\"Исходный текст:\", corpus[0])\n",
    "print(\"Очищенный и лемматизированный текст:\", lemmatize(clear_text(corpus[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestions on impr...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Выводы по первому шагу:**\n",
    ">\n",
    "> В первом шаге были проделаны следующие действия:\n",
    ">  - загрузка данных;\n",
    ">  - изучение общей информации о данных.\n",
    ">\n",
    "> **После загрузки и изучения данных можно сделать несколько выводов:**\n",
    "> 1. лемматизирован и чищен текст;\n",
    "> 2. добавлен в датафрейм столбец с очищенным и лемматизированным текстом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обучение\n",
    "### 2.1 Избавимся от дисбаланса классов и разделим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "condensed_df = df.sample(50000, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "X = condensed_df['lemm_text']\n",
    "y = condensed_df['toxic']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки с использованием стратификации\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, \n",
    "                                                    stratify=y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Построим пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: LogisticRegression\n",
      "Лучшие параметры: {'clf__C': 10}\n",
      "Метрика лучшей модели на обучающей выборке: 0.75\n",
      "Модель: LinearSVC\n",
      "Лучшие параметры: {'clf__C': 1, 'clf__penalty': 'l2'}\n",
      "Метрика лучшей модели на обучающей выборке: 0.76\n",
      "Модель: LGBMClassifier\n",
      "Лучшие параметры: {'clf__max_depth': -1, 'clf__num_leaves': 30}\n",
      "Метрика лучшей модели на обучающей выборке: 0.72\n"
     ]
    }
   ],
   "source": [
    "# List of models with their corresponding parameter grids\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(class_weight='balanced'), {\n",
    "        'clf__C': [0.1, 1, 10]\n",
    "    }),\n",
    "    ('LinearSVC', LinearSVC(), {\n",
    "        'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'clf__penalty': ['l1', 'l2']\n",
    "    }),\n",
    "    ('LightLGBM', LGBMClassifier(), {\n",
    "        'clf__num_leaves': [10, 20, 30],\n",
    "        'clf__max_depth': [5, 10, -1]\n",
    "    })\n",
    "]\n",
    "\n",
    "# Training and evaluation of models\n",
    "results = []\n",
    "\n",
    "for model_name, model, param_grid in models:\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    start_train = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "\n",
    "    # Получаем лучшую модель и её параметры\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Оценка времени предсказания на обучающей выборке\n",
    "    start_pred_train = time.time()\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    end_pred_train = time.time()\n",
    "\n",
    "    # Рассчитываем время обучения и время предсказания\n",
    "    train_time = (end_train - start_train) / 60\n",
    "    pred_train_time = (end_pred_train - start_pred_train) / 60\n",
    "\n",
    "    # Сохраняем результаты\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Params': best_params,\n",
    "        'Best Score': round(grid_search.best_score_, 2),\n",
    "        'Training Time (s)': train_time,\n",
    "        'Prediction Time Train (s)': pred_train_time\n",
    "    })\n",
    "\n",
    "    # Выводим результаты для обучающей выборки\n",
    "    print(f'Модель: {type(model).__name__}')\n",
    "    print(f'Лучшие параметры: {best_params}')\n",
    "    print(f'Метрика лучшей модели на обучающей выборке: {round(grid_search.best_score_, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Prediction Time Train (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'clf__C': 10}</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.150956</td>\n",
       "      <td>0.018961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'l2'}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.315092</td>\n",
       "      <td>0.019082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightLGBM</td>\n",
       "      <td>{'clf__max_depth': -1, 'clf__num_leaves': 30}</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.658257</td>\n",
       "      <td>0.021499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                                    Best Params  \\\n",
       "0  Logistic Regression                                 {'clf__C': 10}   \n",
       "1            LinearSVC            {'clf__C': 1, 'clf__penalty': 'l2'}   \n",
       "2            LightLGBM  {'clf__max_depth': -1, 'clf__num_leaves': 30}   \n",
       "\n",
       "   Best Score  Training Time (s)  Prediction Time Train (s)  \n",
       "0        0.75           0.150956                   0.018961  \n",
       "1        0.76           0.315092                   0.019082  \n",
       "2        0.72           1.658257                   0.021499  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем DataFrame из списка результатов\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Выводим таблицу с результатами\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Оценим метрику лучшей модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и её параметры: Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC(C=1))])\n",
      "F1-мера для лучшей модели на тестовой выборке: 0.77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Получаем лучшие параметры\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Создаем пайплайн с лучшей моделью и ее параметрами\n",
    "best_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC(C=1, penalty='l2'))\n",
    "])\n",
    "\n",
    "# Обучаем лучшую модель на всем обучающем наборе данных\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Оценка качества на тестовой выборке\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Расчет F1-меры на тестовой выборке\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "# Выводим результат для тестовой выборки\n",
    "print(f'Лучшая модель и её параметры: {best_model}')\n",
    "print(f'F1-мера для лучшей модели на тестовой выборке: {f1_test:.2f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Выводы по второму шагу:**\n",
    ">\n",
    "> Во втором шаге были проделаны следующие действия:\n",
    ">  - дисбаланс классов;\n",
    ">  - построен пайплайн.\n",
    ">\n",
    "> **После проведённых действий можно сделать следующие выводы:**\n",
    "> 1. избавились от дисбаланса классов;\n",
    "> 2. обучены 3 модели: **LogisticRegression**, **LinearSVC**, **LGBMClassifier**;\n",
    "> 3. оценена метрика лучшей модели **LinearSVC** на тестовой выборке, по условию значение метрики F1 > 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе исследования был проведен анализ данных для определения оптимального инструмента, способного автоматически обнаруживать токсичные комментарии среди предложенных покупателями правок и комментариев. Для этого были выполнены следующие шаги:\n",
    "\n",
    "**Подготовка данных:** Исходные данные были загружены и предварительно обработаны для дальнейшего анализа.\n",
    "\n",
    "**Выбор моделей:** Был составлен список моделей машинного обучения, которые могли бы быть применены для решения задачи обнаружения токсичных комментариев.\n",
    "\n",
    "**Настройка конвейера:** Для каждой модели был создан конвейер (pipeline), который включал в себя предварительную обработку текста (например, TF-IDF векторизацию) и обучение модели.\n",
    "\n",
    "**Подбор гиперпараметров:** Для каждой модели был проведен поиск по сетке для определения наилучших гиперпараметров с использованием кросс-валидации на обучающем наборе данных.\n",
    "\n",
    "**Обучение моделей:** Наилучшие модели были обучены на обучающем наборе данных с использованием найденных лучших гиперпараметров.\n",
    "\n",
    "**Оценка качества моделей:** Качество каждой модели было оценено с использованием F1-меры на обучающем наборе данных.\n",
    "\n",
    "В ходе исследования было выявлено, что модель LinearSVC показала наилучшее качество среди рассмотренных моделей. Она была выбрана в качестве наилучшей модели для решения задачи обнаружения токсичных комментариев.\n",
    "\n",
    "Для данной модели были подобраны оптимальные гиперпараметры, включая параметры регуляризации (C) и тип регуляризации (penalty). Обученная модель была успешно протестирована на тестовом наборе данных, и ее качество было оценено с использованием F1-меры, которая составила около 0.77.\n",
    "\n",
    "Таким образом, модель LinearSVC с настроенными гиперпараметрами является оптимальным инструментом для автоматического обнаружения токсичных комментариев в интернет-магазине «Викишоп»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чек-лист готовности проекта\n",
    "\n",
    "- [x]  импортированы все необходимые библиотеки.\n",
    "\n",
    "**Шаг 1. Загрузка данных**\n",
    "- [x]  загружены данные;\n",
    "- [x]  изучена общая информация;\n",
    "- [x]  написан вывод.\n",
    "\n",
    "**Шаг 2. Обучение**\n",
    "- [x]  дисбаланс классов;\n",
    "- [x]  построен пайплайн;\n",
    "- [x]  написан вывод.\n",
    "\n",
    "**Общий вывод**\n",
    "- [x]  написан общий вывод;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
